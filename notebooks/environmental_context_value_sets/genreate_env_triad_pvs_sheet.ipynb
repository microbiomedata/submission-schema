{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.004668Z",
     "start_time": "2025-02-24T16:50:40.611930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ],
   "id": "bd353d72cf7850c6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.011695Z",
     "start_time": "2025-02-24T16:50:41.009072Z"
    }
   },
   "cell_type": "code",
   "source": "output_file = 'env_triad_pvs_sheet.tsv'",
   "id": "b354f9d748a2416f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.234822Z",
     "start_time": "2025-02-24T16:50:41.232713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the base directory (current directory)\n",
    "base_dir = Path.cwd()"
   ],
   "id": "fa5b45188e2522dc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.274919Z",
     "start_time": "2025-02-24T16:50:41.271485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find all TSV files recursively with the pattern\n",
    "tsv_files = list(base_dir.rglob(\"post_google_sheets*.tsv\"))"
   ],
   "id": "c86252ede4d744ae",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.338040Z",
     "start_time": "2025-02-24T16:50:41.318949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read and concatenate all matching files into one DataFrame\n",
    "dataframes = []\n",
    "for file in tsv_files:\n",
    "    df = pd.read_csv(file, sep='\\t')  # Read TSV file\n",
    "    df['source_file'] = file.name  # Optionally track the source file\n",
    "    dataframes.append(df)"
   ],
   "id": "5448f378c18966e2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.369954Z",
     "start_time": "2025-02-24T16:50:41.365697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine all dataframes\n",
    "if dataframes:\n",
    "    aggregated_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Aggregated DataFrame created successfully.\")\n",
    "else:\n",
    "    aggregated_df = pd.DataFrame()\n",
    "    print(\"No matching TSV files found.\")"
   ],
   "id": "9a1e57651315937",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame created successfully.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.419314Z",
     "start_time": "2025-02-24T16:50:41.415726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_drop = ['source_file']\n",
    "aggregated_df = aggregated_df.drop(columns=columns_to_drop, axis=1)"
   ],
   "id": "4378d069bc91eb6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.465077Z",
     "start_time": "2025-02-24T16:50:41.461785Z"
    }
   },
   "cell_type": "code",
   "source": "aggregated_df = aggregated_df.rename(columns={'id': 'class_uri'})",
   "id": "7a8486596f143618",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.511002Z",
     "start_time": "2025-02-24T16:50:41.507663Z"
    }
   },
   "cell_type": "code",
   "source": "aggregated_df['title'] = aggregated_df['label']",
   "id": "b3ff53eb825badba",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.578804Z",
     "start_time": "2025-02-24T16:50:41.575213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the new row as a DataFrame\n",
    "new_row = pd.DataFrame([{'class_uri': '> class_uri', 'label': 'class', 'title': 'title'}])\n",
    "\n",
    "# Concatenate the new row with the existing DataFrame\n",
    "schema_sheets_ified = pd.concat([new_row, aggregated_df], ignore_index=True)\n"
   ],
   "id": "61307b08342ea5d7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.624764Z",
     "start_time": "2025-02-24T16:50:41.617139Z"
    }
   },
   "cell_type": "code",
   "source": "schema_sheets_ified.to_csv(output_file, sep='\\t', index=False)",
   "id": "279002211e6c555a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:50:41.664749Z",
     "start_time": "2025-02-24T16:50:41.662751Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "519e4451c48b88d9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
